
from fid.inception import InceptionV3
from fid.fid_score import calculate_activation_statistics, calculate_frechet_distance, get_activations
import torch
import numpy as np


class FIDEstimator(object):
    """
    Fr√©chet Inception Distance for estimation of GAN performance
    It uses features generated by Inception model output on some of the middle layers to
    estimate distance between two image samples
    """
    def __init__(self, noise_sampler, config, limit=10000):
        super().__init__()
        # dimension of inception feature vector for FID
        # can be 64, 192, 768 and 2048
        self.dims = 2048
        self.config = config
        # generator and inception model for FID estimation can be placed on different devices
        self.generator_device = torch.device(config.DEVICE)
        if hasattr(config, 'ESTIMATOR_DEVICE'):
            self.device = torch.device(config.ESTIMATOR_DEVICE)
        else:
            self.device = self.generator_device
        block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[self.dims]
        self.model = InceptionV3([block_idx]).to(self.device).eval()
        self.noise_sampler = noise_sampler
        self.limit = limit
        self.estimator_batch_size = 128

    def score(self, generator, loader):
        """
        Evaluate generator performance computing FID between generator output
        and validation dataset
        :param generator:
        :param loader:
        :return:
        """
        generator.eval()
        act_real = []
        act_fake = []
        num_batches = self.limit // loader.batch_size + 1
        for idx, sample in zip(range(num_batches), loader):
            noise = self.noise_sampler.sample_batch(sample[0].shape[0])
            noise = [c.to(self.generator_device) for c in noise]
            # rescale generator output from [-1, 1] to [0, 1]
            G_sample = (generator(*noise) + 1)/2
            # transfer tensor from generator device to device with Inception model
            G_sample = G_sample.to(self.device)
            with torch.cuda.device(self.device.index):
                act_real_batch = get_activations(((sample[0] + 1)/2).cuda(), self.model, batch_size=self.estimator_batch_size, dims=self.dims, cuda=1)
                act_fake_batch = get_activations(G_sample, self.model, batch_size=self.estimator_batch_size, dims=self.dims, cuda=1)
                act_real.append(act_real_batch)
                act_fake.append(act_fake_batch)
            del G_sample, sample

        act_real = np.concatenate(act_real)
        act_fake = np.concatenate(act_fake)
        # calculate activation statistics
        m1 = np.mean(act_real, axis=0)
        s1 = np.cov(act_real, rowvar=False)
        m2 = np.mean(act_fake, axis=0)
        s2 = np.cov(act_fake, rowvar=False)
        fid_value = calculate_frechet_distance(m1, s1, m2, s2)
        return fid_value

    def distance(self, X1, X2):
        assert(X1.shape == X2.shape)
        # Generator outputs images with pixel values in [-1, 1]
        # While inception expect them to be in range [0, 1]
        # Inplace operations are used to save memory usage as X1 and X2 can be very big
        X1 += 1
        X1 /= 2
        X2 += 1
        X2 /= 2
        with torch.cuda.device(self.device.index):
            m1, s1 = calculate_activation_statistics(X1, self.model, batch_size=self.estimator_batch_size, dims=self.dims, cuda=1)
            m2, s2 = calculate_activation_statistics(X2, self.model, batch_size=self.estimator_batch_size, dims=self.dims, cuda=1)
            fid_value = calculate_frechet_distance(m1, s1, m2, s2)
        return fid_value


